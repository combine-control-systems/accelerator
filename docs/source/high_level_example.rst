High Level Example Project
--------------------------

This section provides a high level example to get an idea on how to
use exax in a project, and how to partition the code into build and
job scripts.



Example
=======

Assume a project dealing with training some machine learning model on
a given dataset.  The input data is stored in a format that needs some
parsing, and some cleanup of the data is necessary as well.

Here is an idea of what the build script may look like.

.. code-block::
   :caption: Example build script

    def main(urd):
        pdata = urd.build('parse', filename='input_filename')
	clean = urd.build('clean', data=pdata)
	train = urd.build('train', data=clean)
	plot1 = urd.build('plot_train', input=train)
	plot2 = urd.build('plot_data', input=clean)
	plot1.link_result('graph.png')

Each ``urd.build`` function calls a job script with a parameter list.
For example, the third line will call the ``clean`` job script, and
set its input parameter `data` to the value ``pdata``, which is the
resulting job object output from the ``parse`` job script call on the
line above.  And so on.

The last line makes the ``graph.png`` file from the ``plot_data``
script directly visible in the board web server (and also in the
``results/``-directory in the project installation directory.



Why exax?
=========

Partitioning a project into separate independent functions is an
obvious thing to do.  What is improved by using exax?  What are the benefits?


- *We kan trivially validate that the everything is up-to-date and that the
  ``graph.png`` file corresponds to the current source code version.*

  This is done by simply running the build script.  If it completes in
  a fraction of a second without building any job scripts, then
  everything was up-to-date.  If, on the other hand, there are
  changes, these changes will be executed and everything will be
  up-to-date after execution.

  So this is somehow contrary to how to do it traditionally.  Traditionally,
  one needs to "run everything" to "ensure it is up to date".  With exax,
  everything is up-to-date if nothing needs to be executed.


- *Development is faster if the project is partitioned into a set of
  sequentially executed job scripts.*

  Once a script is working, it does not need to be executed again, and
  all computational effort is spent on the next "active" job script
  that is currently under development.

  For example, if we make visual changes to the graph in the
  ``plot_train`` script, only this script needs to be executed.  All
  previous scripts are already represented by files on disk.


- *The risks associated with temporary intermediate files are gone.*

  Common traditional problems include reading the wrong file (giving
  the impression that your change did not break anything) or
  overwriting the wrong file (that took hours to generate).  These
  problems do not exist in the exax framework, since exax refer by job
  (i.e. source code and input parameters), and not by filename.

  Plotting the data generated by the "train" job script is safer and
  makes much more sense than plotting the data in a file named
  "output_from_train_job_20250202_working_final_2".

  The only filename explicitly mentioned in the example script above
  is the input filename.


- *All previous runs are stored and can be retrieved at any time.*

  This includes source code.  We can go back and find produced results
  *and* the corresponding source code of any code execution in the
  project.

  Thus, we can find result and source code for the version that we run
  yesterday before lunch that produced those great results but
  unfortunately was not version controlled.  Exax has your back.


- *Parallel processing is easy to do, and really speeds things up.*

  Exax is designed for naive parallel processing, where a set of
  processes run in parallel without inter-process communicaation.  It
  is not suitable for all kinds of problems, but for a surprisingly
  large subset.

  Some examples where it works:

  - *row-parallel processing of large datasets*
    (Count occurances, combine columns, etc.)

  - *running a function on several independent input files in parallel*
    (A machine lerning model applied to several datasets.)

  - *running different functions on the same input file*
    (Train a machine learning model with different hyperparameters.)

  - *generating animation video frames in parallel*
    (Combine frames later in the right order to generate a video file.)


- *Collaboration can be really efficient in computationally exepensive projects*

  Only the first developer executing a new script will need to wait
  for the execution to complete.  All other users will just get a
  reference to the existing job in a fraction of a second.  This works
  by sharing workdirs between the users.

  Another example is doing analysis of a production environment.  A
  user doing some analysis work can access the jobs created by the
  actual production system and use them directly in the analysis.  It
  is then the *actual* production system that is analysed, not some
  copy, and since it reads existing jobs it is very fast.



Some Example Project where Exax has been used
=============================================

- multiple production environments for large recommender systems
- a large collaborative filtering project
- a mining optimisation system
- a churn prediction project
- a SLAM hardware accelerator project
- a zfs backup framework
- a video visualisation of NYC cab traffic during Covid 19
- a video visuaisation of all the Backblaze data
- various radio data projects with huge datasets and multiple code versions
- various machine learning projects with for example video input
- an EEG data analysis project
